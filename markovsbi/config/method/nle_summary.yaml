backend: torch
name: 'nle_summary'
device: cpu 
subseq_data_augmentation_fraction: 1.
params_train:
  training_batch_size: 1000
  learning_rate: 1e-3
  validation_fraction: 0.1
  stop_after_epochs: 20
  max_num_epochs: 2147483647
  clip_max_norm: 5.
params_build_posterior:
  sample_with: 'mcmc'
  mcmc_method: 'slice_np_vectorized'
  mcmc_parameters:
    num_chains: 100
    init_strategy_parameters:
      num_candidate_samples: 10
params_init:
  density_estimator: 'maf'
neural_net.num_layers: 1



defaults:
  - _self_
  - neural_net: "rnn_embedding"
  - sampler: mcmc